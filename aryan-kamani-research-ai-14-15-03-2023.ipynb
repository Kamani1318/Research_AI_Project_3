{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-13T12:11:15.295822Z","iopub.execute_input":"2023-03-13T12:11:15.296220Z","iopub.status.idle":"2023-03-13T12:11:15.353859Z","shell.execute_reply.started":"2023-03-13T12:11:15.296186Z","shell.execute_reply":"2023-03-13T12:11:15.352507Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mnist-in-csv/mnist_test.csv\n/kaggle/input/mnist-in-csv/mnist_train.csv\n/kaggle/input/mnist-train/mnist_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nimport time\nfrom torch.utils.data import random_split\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import MNIST\nfrom torchvision.transforms import ToTensor\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:11:18.036369Z","iopub.execute_input":"2023-03-13T12:11:18.036862Z","iopub.status.idle":"2023-03-13T12:11:21.506796Z","shell.execute_reply.started":"2023-03-13T12:11:18.036806Z","shell.execute_reply":"2023-03-13T12:11:21.505110Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"torch_X_train = torch.from_numpy(x_train).type(torch.LongTensor)\ntorch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for test set.\ntorch_X_test = torch.from_numpy(x_test).type(torch.LongTensor)\ntorch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n\n# Pytorch train and test sets (tensor objects)\ntrain = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\ntest = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)","metadata":{}},{"cell_type":"code","source":"mnist_train = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\nmnist_test = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:11:27.256781Z","iopub.execute_input":"2023-03-13T12:11:27.257435Z","iopub.status.idle":"2023-03-13T12:11:35.129701Z","shell.execute_reply.started":"2023-03-13T12:11:27.257391Z","shell.execute_reply":"2023-03-13T12:11:35.128463Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"y_train,x_train = mnist_train['label'].values, mnist_train.iloc[:,1:].values\ny_test,x_test = mnist_test['label'].values,mnist_test.iloc[:,1:].values","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:11:40.868899Z","iopub.execute_input":"2023-03-13T12:11:40.870030Z","iopub.status.idle":"2023-03-13T12:11:40.883189Z","shell.execute_reply.started":"2023-03-13T12:11:40.869975Z","shell.execute_reply":"2023-03-13T12:11:40.882017Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"INIT_LR = 1e-3\nBATCH_SIZE = 64\nEPOCHS = 10\nTRAIN_SPLIT = 0.75\nVAL_SPLIT = 1- TRAIN_SPLIT\ndevice = torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n\ntorch_X_train = torch.from_numpy(x_train).type(torch.LongTensor)\ntorch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n\n# create feature and targets tensor for test set.\ntorch_X_test = torch.from_numpy(x_test).type(torch.LongTensor)\ntorch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long\n\n# Pytorch train and test sets (tensor objects)\ntrain = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\ntest = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n\nnumTrainSamples = int(len(train)*TRAIN_SPLIT)\nnumValSamples = int(len(train)*VAL_SPLIT)\n(trainData,valData) = random_split(train,[numTrainSamples,numValSamples],generator = torch.Generator().manual_seed(42))\n\n# data loader object\ntrain_loader = torch.utils.data.DataLoader(trainData, batch_size = BATCH_SIZE, shuffle = False)\nval_loader = torch.utils.data.DataLoader(valData, batch_size = BATCH_SIZE, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n\n#calculkate steps per epcoh for training and validation set\ntrainSteps = len(train_loader.dataset)\nvalSteps = len(val_loader.dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:11:48.538756Z","iopub.execute_input":"2023-03-13T12:11:48.539199Z","iopub.status.idle":"2023-03-13T12:11:48.588860Z","shell.execute_reply.started":"2023-03-13T12:11:48.539162Z","shell.execute_reply":"2023-03-13T12:11:48.587821Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class LeNet(nn.Module):\n    def __init__(self,numChannels,classes):\n        #call the parent constructor\n        super(LeNet,self).__init__()\n        #initialise first set of convolutions\n        self.conv1 = nn.Conv2d(in_channels = numChannels, out_channels = 20,kernel_size = (5,5))\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2),stride = (2,2))\n        \n        #initialise second set of convolutions\n        \n        self.conv2 = nn.Conv2d(in_channels = 20,out_channels = 50,kernel_size = (5,5))\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size = (2,2),stride = (2,2))\n        \n        #initialise first set of FC \n        self.fc1 = nn.Linear(in_features = 800,out_features = 500)\n        self.relu3 = nn.ReLU()\n        \n        #initialise softmax classifier\n        self.fc2 = nn.Linear(in_features=500,out_features = classes)\n        self.logSoftmax = nn.LogSoftmax(dim = 1)\n    def forward(self,x):\n        x = x.to(torch.float)\n        x = x.view(1,64,28,28)\n        print(x.shape)\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n    \n    # pass the output from the previous layer through the second\n    # set of CONV => RELU => POOL layers\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n    \n    # flatten the output from the previous layer and pass it\n    # through our only set of FC => RELU layers\n        x = flatten(x, 1)\n        x = self.fc1(x)\n        x = self.relu3(x)\n    \n    # pass the output to our softmax classifier to get our output\n    # predictions\n        x = self.fc2(x)\n        output = self.logSoftmax(x)\n    \n    # return the output predictions\n        return output\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:15:39.462582Z","iopub.execute_input":"2023-03-13T12:15:39.462982Z","iopub.status.idle":"2023-03-13T12:15:39.479750Z","shell.execute_reply.started":"2023-03-13T12:15:39.462950Z","shell.execute_reply":"2023-03-13T12:15:39.477857Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print('Initialising the lenet model')\nmodel = LeNet(numChannels = 1,classes=10)\n\n#initialising optimizer and loss function\nopt = Adam(model.parameters(),lr = INIT_LR)\n# cross entropy loss\nlossFn = nn.NLLLoss()\n#initialising a dictionary to store training history\nH = {\"train_loss\":[],\n    \"train_acc\":[],\n    \"val_loss\":[],\n    \"val_acc\":[]\n    }\nprint('training the network')\n# starting out timer\nstartTime = time.time()","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:15:14.115115Z","iopub.execute_input":"2023-03-13T12:15:14.115539Z","iopub.status.idle":"2023-03-13T12:15:14.128275Z","shell.execute_reply.started":"2023-03-13T12:15:14.115479Z","shell.execute_reply":"2023-03-13T12:15:14.127047Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Initialising the lenet model\ntraining the network\n","output_type":"stream"}]},{"cell_type":"code","source":"for e in range(EPOCHS):\n    model.train()\n    totalTrainLoss = 0\n    totalValLoss = 0\n    trainCorrect = 0\n    valCorrect = 0\n    for(x,y) in train_loader:\n        (x,y) = (x.to(device),y.to(device))\n        # forward pass\n        pred = model(x)\n        loss = lossFn(pred,y)\n        # zero out the gradients, perform backpropagation and update weights\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n        # add loss to total training losss\n        # calculate the number of correct predictions\n        totalTrainLoss = totalTrainLoss + loss\n        trainCorrect = trainCorrect + (pred.argmax(1)==y).type(torch.float).sum().item()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-03-13T12:15:15.764302Z","iopub.execute_input":"2023-03-13T12:15:15.764704Z","iopub.status.idle":"2023-03-13T12:15:15.820918Z","shell.execute_reply.started":"2023-03-13T12:15:15.764669Z","shell.execute_reply":"2023-03-13T12:15:15.819105Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3666872279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# zero out the gradients, perform backpropagation and update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1811272540.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [20, 1, 5, 5], expected input[1, 64, 28, 28] to have 1 channels, but got 64 channels instead"],"ename":"RuntimeError","evalue":"Given groups=1, weight of size [20, 1, 5, 5], expected input[1, 64, 28, 28] to have 1 channels, but got 64 channels instead","output_type":"error"}]},{"cell_type":"code","source":"with torch.no_grad():\n    model.eval()\n    for (x,y) in valDataLoader:\n        (x,y) = (x.to(device),y.to(device))\n        pred = model(x)\n        totalValLoss = totalValLoss + lossFn(pred,y)\n        valCorrect += (pred.argmax(1)==y).type(torch.float).sum().item()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_lenet():\n    model = nn.Sequential(\n        nn.Conv2d(1, 6, 5, padding=2),\n        nn.ReLU(),\n        nn.AvgPool2d(2, stride=2),\n        nn.Conv2d(6, 16, 5, padding=0),\n        nn.ReLU(),\n        nn.AvgPool2d(2, stride=2),\n        nn.Flatten(),\n        nn.Linear(400, 120),\n        nn.ReLU(),\n        nn.Linear(120, 84),\n        nn.ReLU(),\n        nn.Linear(84, 10)\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:11.696409Z","iopub.execute_input":"2023-03-07T05:37:11.696846Z","iopub.status.idle":"2023-03-07T05:37:11.704434Z","shell.execute_reply.started":"2023-03-07T05:37:11.696810Z","shell.execute_reply":"2023-03-07T05:37:11.703368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7,7))\nidx = 10\ngrid_data = x.iloc[idx].values.reshape(28,28)\nplt.imshow(grid_data,interpolation = 'none', cmap = 'gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:12.063235Z","iopub.execute_input":"2023-03-07T05:37:12.063690Z","iopub.status.idle":"2023-03-07T05:37:12.294323Z","shell.execute_reply.started":"2023-03-07T05:37:12.063649Z","shell.execute_reply":"2023-03-07T05:37:12.293334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, data):\n    total = 0\n    correct = 0\n    for i, (images, labels) in enumerate(data):\n        images = images.cuda()\n        x = model(images)\n        value, pred = torch.max(x,1)\n        pred = pred.data.cpu()\n        total += x.size(0)\n        correct += torch.sum(pred == labels)\n    return correct*100./total","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:14.721346Z","iopub.execute_input":"2023-03-07T05:37:14.722776Z","iopub.status.idle":"2023-03-07T05:37:14.731522Z","shell.execute_reply.started":"2023-03-07T05:37:14.722715Z","shell.execute_reply":"2023-03-07T05:37:14.730064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(numb_epoch=3, lr=1e-3, device=\"cpu\"):\n    accuracies = []\n    cnn = create_lenet().to(device)\n    cec = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(cnn.parameters(), lr=lr)\n    max_accuracy = 0\n    for epoch in range(numb_epoch):\n        for images,labels in enumerate(mnist_train):\n            images = images.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            pred = cnn(images)\n            loss = cec(pred, labels)\n            loss.backward()\n            optimizer.step()\n        accuracy = float(validate(cnn,mnist_test))\n        accuracies.append(accuracy)\n        if accuracy > max_accuracy:\n            best_model = copy.deepcopy(cnn)\n            max_accuracy = accuracy\n            print(\"Saving Best Model with Accuracy: \", accuracy)\n        print('Epoch:', epoch+1, \"Accuracy :\", accuracy, '%')\n    plt.plot(accuracies)\n    return best_model","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:15.520265Z","iopub.execute_input":"2023-03-07T05:37:15.520680Z","iopub.status.idle":"2023-03-07T05:37:15.530162Z","shell.execute_reply.started":"2023-03-07T05:37:15.520644Z","shell.execute_reply":"2023-03-07T05:37:15.528897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda:0')\nelse:\n    device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:16.582400Z","iopub.execute_input":"2023-03-07T05:37:16.583434Z","iopub.status.idle":"2023-03-07T05:37:16.589384Z","shell.execute_reply.started":"2023-03-07T05:37:16.583373Z","shell.execute_reply":"2023-03-07T05:37:16.588090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:17.011010Z","iopub.execute_input":"2023-03-07T05:37:17.012302Z","iopub.status.idle":"2023-03-07T05:37:17.019907Z","shell.execute_reply.started":"2023-03-07T05:37:17.012244Z","shell.execute_reply":"2023-03-07T05:37:17.018410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lenet = train(40,device = device)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T05:37:18.022563Z","iopub.execute_input":"2023-03-07T05:37:18.023305Z","iopub.status.idle":"2023-03-07T05:37:18.057339Z","shell.execute_reply.started":"2023-03-07T05:37:18.023262Z","shell.execute_reply":"2023-03-07T05:37:18.055500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}