{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd23c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32528767",
   "metadata": {},
   "source": [
    "Importing the data. We see that we have to classify 10 images. Hence it is a multiclass classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff3eeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fashion-mnist_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f04022",
   "metadata": {},
   "source": [
    "Converting the dataframe into a numpy array and getting the number of rows and columns for the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5262e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m,n = data.shape\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2f64f",
   "metadata": {},
   "source": [
    "Dividing data into development and training data. Dividing data into input and labels too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e0d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev/255\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train/255\n",
    "a,b = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714988fe",
   "metadata": {},
   "source": [
    "We are creating a neural network with one input layer of 784 neurons , one hidden layer of 10 neurons and the output layer has 10 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2a89f",
   "metadata": {},
   "source": [
    "Creating a function that initialises the parameters w1,b1,w2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bc4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    \n",
    "    w1 = np.random.uniform(-0.5,0.5,size = (10,784))\n",
    "    b1 = np.random.uniform(-0.5,0.5, size = (10,1))\n",
    "    w2 = np.random.uniform(-0.5,0.5,size = (10,10))\n",
    "    b2 = np.random.uniform(-0.5,0.5, size = (10,1))\n",
    "    return w1,b1,w2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca58654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,b1,w2,b2 = init_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50552f",
   "metadata": {},
   "source": [
    "Definng the activatin functions ReLU and Softmax. I used ReLU and Softmax as ReLU is the most generally used activation function for hidden layers, and softmax is best used for multiclassification problems like this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4683db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59617178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    e = np.exp(Z)\n",
    "    return e/np.sum(e,axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b8cae",
   "metadata": {},
   "source": [
    "Defining the forward propagation function. Z1 is the output of input layer, Z2 is the output of the hidden layer and A2 is the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498dade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(w1,b1,w2,b2,X):\n",
    "    Z1 = w1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = w2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1,A1,Z2,A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d7da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1,A1,Z2,A2 = forward_prop(w1,b1,w2,b2,X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c2962",
   "metadata": {},
   "source": [
    "We defined a onehotencoder function as the labels are numbers ranging from 0-9. We need to convert each number into an array of zeros and ones to match the actual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f30998c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder(Y):\n",
    "    one_hot_Y = np.zeros((Y.size,Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size),Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "931ab5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_ReLU(Z):\n",
    "    return Z >0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4e6d3",
   "metadata": {},
   "source": [
    "For the backpropagation function, the Loss function is defined as (y_predicted - y-train) for simple differentiation\n",
    "L2 regularisation is used as the model is simple enough and the aim is to reduce the value of weights to solve the problem of vanishing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9fc9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(Z1,A1,Z2,A2,X,Y,w2,reg_par):\n",
    "    m = Y.size\n",
    "    one_hot_Y = onehotencoder(Y)\n",
    "    l2_reg_exp = (1/(2*m))*reg_par*(np.sum(np.square(w2)) + np.sum(np.square(w1)))\n",
    "    dZ2 = (A2 - one_hot_Y) + l2_reg_exp\n",
    "    loss = np.sum((A2-one_hot_Y)) + l2_reg_exp\n",
    "    dw2 = 1/m*(dZ2.dot(A1.T)) + 1/m*reg_par*np.sum(w2)\n",
    "    \n",
    "    db2 = 1/m*(np.sum(dZ2)) \n",
    "    \n",
    "    dZ1 = w2.T.dot(dZ2)*deriv_ReLU(Z1) \n",
    "    \n",
    "    dw1 = 1/m*(dZ2.dot(X.T))+ 1/m*reg_par*np.sum(w1)\n",
    "    \n",
    "    db1 = 1/m*(np.sum(dZ1))\n",
    "    return dw1,dw2,db1,db2,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bf7dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw1,dw2,db1,db2,loss = backprop(Z1,A1,Z2,A2,X_train,Y_train,w2,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ae930",
   "metadata": {},
   "source": [
    "Updating the parameters with the derivatives and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34fd438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(w1,b1,w2,b2,dw1,db1,dw2,db2,alpha):\n",
    "    w1 = w1 - alpha*dw1\n",
    "    b1 = b1 - alpha*db1\n",
    "    w2 = w2 - alpha*dw2\n",
    "    b2 = b2 - alpha*db2\n",
    "    return w1,b1,w2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9e3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eab5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y)/Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08dc617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8802d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,iterations,alpha):\n",
    "    w1,b1,w2,b2 = init_params()\n",
    "    reg_par = 0.01\n",
    "    for i in range(iterations):\n",
    "        Z1,A1,Z2,A2 = forward_prop(w1,b1,w2,b2,X)\n",
    "        dw1,dw2,db1,db2,loss = backprop(Z1,A1,Z2,A2,X,Y,w2,reg_par)\n",
    "        w1,b1,w2,b2 = update_params(w1,b1,w2,b2,dw1,db1,dw2,db2,alpha)\n",
    "        arg_A2 = get_predictions(A2)\n",
    "        # printing the accuracy and loss of model after every 100 iterations\n",
    "        if i%100 == 0 :\n",
    "            print('Iteration', i)\n",
    "            print('Accuracy',accuracy_score(arg_A2, Y))\n",
    "            print('The loss is:',loss)\n",
    "    return w1,b1,w2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cf15faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Accuracy 0.0796271186440678\n",
      "The loss is: 5.6027497985526355e-05\n",
      "Iteration 100\n",
      "Accuracy 0.627542372881356\n",
      "The loss is: 5.606306684400931e-05\n",
      "Iteration 200\n",
      "Accuracy 0.681728813559322\n",
      "The loss is: 5.62351190041673e-05\n",
      "Iteration 300\n",
      "Accuracy 0.6810508474576271\n",
      "The loss is: 5.630942920142334e-05\n",
      "Iteration 400\n",
      "Accuracy 0.659728813559322\n",
      "The loss is: 5.6380753862059365e-05\n",
      "Iteration 500\n",
      "Accuracy 0.7187627118644068\n",
      "The loss is: 5.64378771379986e-05\n",
      "Iteration 600\n",
      "Accuracy 0.7379152542372881\n",
      "The loss is: 5.645268937805839e-05\n",
      "Iteration 700\n",
      "Accuracy 0.7737118644067796\n",
      "The loss is: 5.645698033708245e-05\n",
      "Iteration 800\n",
      "Accuracy 0.7842542372881356\n",
      "The loss is: 5.646564461861436e-05\n",
      "Iteration 900\n",
      "Accuracy 0.7932203389830509\n",
      "The loss is: 5.646671673643861e-05\n",
      "Iteration 1000\n",
      "Accuracy 0.8006101694915254\n",
      "The loss is: 5.6467593535862996e-05\n",
      "Iteration 1100\n",
      "Accuracy 0.8062372881355933\n",
      "The loss is: 5.647095454996228e-05\n",
      "Iteration 1200\n",
      "Accuracy 0.8102372881355933\n",
      "The loss is: 5.6476245010145655e-05\n",
      "Iteration 1300\n",
      "Accuracy 0.813864406779661\n",
      "The loss is: 5.64827094869883e-05\n",
      "Iteration 1400\n",
      "Accuracy 0.8163898305084746\n",
      "The loss is: 5.648997087878408e-05\n",
      "Iteration 1500\n",
      "Accuracy 0.8185254237288135\n",
      "The loss is: 5.649784417260605e-05\n",
      "Iteration 1600\n",
      "Accuracy 0.8205084745762712\n",
      "The loss is: 5.650613495393667e-05\n",
      "Iteration 1700\n",
      "Accuracy 0.8221864406779661\n",
      "The loss is: 5.6514683930126415e-05\n",
      "Iteration 1800\n",
      "Accuracy 0.8237457627118644\n",
      "The loss is: 5.652339401628629e-05\n",
      "Iteration 1900\n",
      "Accuracy 0.8256101694915254\n",
      "The loss is: 5.653217900261765e-05\n"
     ]
    }
   ],
   "source": [
    "w1,b1,w2,b2 = gradient_descent(X_train,Y_train,2000,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97122a96",
   "metadata": {},
   "source": [
    "From what we can observe, the model works fine on using the training data.\n",
    "However, too many iterations are needed to increase the accuracy of the model, so optimisation is recquired.\n",
    "The model does not get stuck at one local minima on running it multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3c3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
